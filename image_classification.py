# -*- coding: utf-8 -*-
"""Image Classification

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/image-classification-7cc81f39-cfe2-4001-816b-9a2af0f913bf.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20240508/auto/storage/goog4_request%26X-Goog-Date%3D20240508T112756Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D00a56129e27a4b398fd40882d0a124cfdf0f7a381e103de64ae9fa193ff21412bc8a03ec51492e29cab08c25f0968bdf00a4750dda50ec22b4606e279a06056c1fcf882b742aa6b0d4963c8bc2a77cd2e48e4de1181940b4eea6555dc66dc4a21a51b1cea7c5c05295222602ec751b3b531fa7a1ff176e6fa27ede4210dbc1c8470bf35a9d41ccdc67acf6784615ee762ff41aad022c2b000d8be921e5b69cdfa047bb864a67b09e433823c2cf975292e3d47b6009d444d3f6e467b13bef2e7de23aaf36391016ee23fb927e0757b9cada34ade97c420d1ed2dcb97733c8acf2aeb0bad0e5011548c9c43c0e42c52521982832688eb747f31f05a35fff27c72c
"""

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES
# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.

import os
import sys
from tempfile import NamedTemporaryFile
from urllib.request import urlopen
from urllib.parse import unquote, urlparse
from urllib.error import HTTPError
from zipfile import ZipFile
import tarfile
import shutil

CHUNK_SIZE = 40960
DATA_SOURCE_MAPPING = 'cards-image-datasetclassification:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F2579480%2F4532039%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240508%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240508T112756Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D7921539e499c65cb828f490f3ef3516fcf832fb13c47d2a6b8fa35460ac268ba8a1ae8ae36785d73e2aa4848761c8e6afcff0dc067e13b22f8bf7f2947ae599a40e7c40b4661c97d76de4c91d0907afc6d270340b875823fb58923a8b169026aac18c31e352cc3562019c50ce6725e72939bdb5916e124a23df1cef1b307fb5207eb1a5165da09b0ef630e82a616a2a72a1e8fe65f0aec636f71e4cea74c878dabbf3c61a6728b7d2f811353e0636236f47df01a599df4e6582430bcee70e2f63f1df7bc38cb38e48d17e0c2d1543f9554f37e811f252fde5496fe65b88b2d845dfde60ad2436d159c79eff61c18f1941e3aad563e375d776c58c7e9ddb361fc'

KAGGLE_INPUT_PATH='/kaggle/input'
KAGGLE_WORKING_PATH='/kaggle/working'
KAGGLE_SYMLINK='kaggle'

!umount /kaggle/input/ 2> /dev/null
shutil.rmtree('/kaggle/input', ignore_errors=True)
os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)
os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)

try:
  os.symlink(KAGGLE_INPUT_PATH, os.path.join("..", 'input'), target_is_directory=True)
except FileExistsError:
  pass
try:
  os.symlink(KAGGLE_WORKING_PATH, os.path.join("..", 'working'), target_is_directory=True)
except FileExistsError:
  pass

for data_source_mapping in DATA_SOURCE_MAPPING.split(','):
    directory, download_url_encoded = data_source_mapping.split(':')
    download_url = unquote(download_url_encoded)
    filename = urlparse(download_url).path
    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)
    try:
        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:
            total_length = fileres.headers['content-length']
            print(f'Downloading {directory}, {total_length} bytes compressed')
            dl = 0
            data = fileres.read(CHUNK_SIZE)
            while len(data) > 0:
                dl += len(data)
                tfile.write(data)
                done = int(50 * dl / int(total_length))
                sys.stdout.write(f"\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded")
                sys.stdout.flush()
                data = fileres.read(CHUNK_SIZE)
            if filename.endswith('.zip'):
              with ZipFile(tfile) as zfile:
                zfile.extractall(destination_path)
            else:
              with tarfile.open(tfile.name) as tarfile:
                tarfile.extractall(destination_path)
            print(f'\nDownloaded and uncompressed: {directory}')
    except HTTPError as e:
        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')
        continue
    except OSError as e:
        print(f'Failed to load {download_url} to path {destination_path}')
        continue

print('Data source import complete.')

"""## Image Classification using Deep Learning"""

pip install timm

# import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torchvision
import torchvision.transforms as transforms
from torchvision.datasets import ImageFolder
import timm

from tqdm.notebook import tqdm

"""## Step 1: Load Pytorch Dataset"""

class CardDataset(Dataset):
    def __init__(self, data_dir, transform=None):
        self.data = ImageFolder(data_dir, transform=transform)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, index):
        return self.data[index]

    @property
    def classes(self):
        return self.data.classes

# create an object
train_data = CardDataset(data_dir='/kaggle/input/cards-image-datasetclassification/train')

len(train_data)

train_data[0]

image, label = train_data[0]
print(label)
image

# get a dictionary
data_dir = '/kaggle/input/cards-image-datasetclassification/train'
label_to_class = {value: key for key, value in ImageFolder(data_dir).class_to_idx.items()}
label_to_class

# implement a transformation
transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor()
])

train_data = CardDataset(data_dir, transform=transform)

tensor, label = train_data[0]
print(label)
tensor

tensor.shape

"""## Implement dataloader"""

train_data_loader = DataLoader(train_data, batch_size=32, shuffle=True)

for images, labels in train_data_loader:
    break

images.shape

labels.shape

"""## Step 2: Building Neural Network"""

class SimpleCardClassifer(nn.Module):
    def __init__(self, num_classes=53):
        super(SimpleCardClassifer, self).__init__()
        # Where we define all the parts of the model
        self.base_model = timm.create_model('efficientnet_b0', pretrained=True)
        self.features = nn.Sequential(*list(self.base_model.children())[:-1])

        enet_out_size = 1280
        # Make a classifier
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(enet_out_size, num_classes)
        )

    def forward(self, x):
        # Connect these parts and return the output
        x = self.features(x)
        output = self.classifier(x)
        return output

model = SimpleCardClassifer(num_classes=53)
print(str(model)[:500])

import matplotlib.pyplot as plt
from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix
import seaborn as sns

# Calculate confusion matrix
cm = confusion_matrix(all_labels, all_predictions)

# Define class labels for display
class_labels = list(label_to_class.values())

# Plot confusion matrix
plt.figure(figsize=(12, 10))
sns.set(font_scale=1.4)  # Increase font size for better readability
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()

from PIL import Image
import torchvision.transforms as transforms

# Define the transformation for the input image
transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor()
])

# Load and preprocess the image
image_path = '/content/sample_data/OIP.jpeg'
image = Image.open(image_path).convert("RGB")
image_tensor = transform(image).unsqueeze(0)

# Perform inference
with torch.no_grad():
    output = model(image_tensor)

# Get the predicted class
predicted_class_idx = torch.argmax(output).item()
predicted_class = label_to_class[predicted_class_idx]

# Display the result
print(f"Predicted Class: {predicted_class}")

